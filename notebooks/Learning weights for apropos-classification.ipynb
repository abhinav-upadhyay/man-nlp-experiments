{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/newst_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'name', 'section', 'rank', 'indegree', 'outdegree', 'w_name',\n",
       "       'w_name_desc', 'w_desc', 'w_lib', 'w_return_vals', 'w_env', 'w_files',\n",
       "       'w_exit_status', 'w_diagnostics', 'w_errors', 'w_special_keywords',\n",
       "       'w_xr_context', 'w_machine', 'w_doclen', 'w_total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"query\"] = data[\"query\"].astype(\"category\")\n",
    "data[\"w_doclen\"] = data[\"w_doclen\"].astype(\"int\")\n",
    "data[\"section\"] = data[\"section\"].astype(\"category\")\n",
    "data[\"name\"] = data[\"name\"].astype(\"category\")\n",
    "data[\"section\"] = data[\"section\"].cat.codes\n",
    "#data[\"rank\"] = data[\"rank\"].astype(\"int\")\n",
    "#data.rank[data.rank <= 1] = 0\n",
    "#data.rank[data.relevance == 2] = 1\n",
    "#data.rank[data.rank >= 2] = 1\n",
    "#data.loc[data['rank'] <= 1, 'rank'] = 0\n",
    "#data.loc[data['rank'] == 2, 'rank'] = 1\n",
    "#data.loc[data['rank'] >= 2, 'rank'] = 2\n",
    "data[\"rank\"] = data[\"rank\"].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>name</th>\n",
       "      <th>section</th>\n",
       "      <th>rank</th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>w_name</th>\n",
       "      <th>w_name_desc</th>\n",
       "      <th>w_desc</th>\n",
       "      <th>w_lib</th>\n",
       "      <th>...</th>\n",
       "      <th>w_env</th>\n",
       "      <th>w_files</th>\n",
       "      <th>w_exit_status</th>\n",
       "      <th>w_diagnostics</th>\n",
       "      <th>w_errors</th>\n",
       "      <th>w_special_keywords</th>\n",
       "      <th>w_xr_context</th>\n",
       "      <th>w_machine</th>\n",
       "      <th>w_doclen</th>\n",
       "      <th>w_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abor</td>\n",
       "      <td>ftpd</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>43</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500493</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.501308</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3535</td>\n",
       "      <td>0.622490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abor</td>\n",
       "      <td>ftp</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.502630</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8336</td>\n",
       "      <td>0.622510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abort</td>\n",
       "      <td>kcopy</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.501739</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>74</td>\n",
       "      <td>0.630843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abort</td>\n",
       "      <td>abort</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.504899</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.806442</td>\n",
       "      <td>0.720238</td>\n",
       "      <td>0.5</td>\n",
       "      <td>147</td>\n",
       "      <td>0.647684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abort</td>\n",
       "      <td>wait</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1229</td>\n",
       "      <td>0.623353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   query   name  section rank  indegree  outdegree  w_name  w_name_desc  \\\n",
       "0   abor   ftpd        8    4        27         43     0.5     0.500000   \n",
       "1   abor    ftp        0    4        23         17     0.5     0.500000   \n",
       "2  abort  kcopy        9    3         1          4     0.5     0.999945   \n",
       "3  abort  abort        2    4        16          2     1.0     0.500000   \n",
       "4  abort   wait        1    0        20          0     0.5     0.500000   \n",
       "\n",
       "     w_desc  w_lib    ...     w_env  w_files  w_exit_status  w_diagnostics  \\\n",
       "0  0.500493    0.5    ...       0.5      0.5            0.5            0.5   \n",
       "1  0.500375    0.5    ...       0.5      0.5            0.5            0.5   \n",
       "2  0.501739    0.5    ...       0.5      0.5            0.5            0.5   \n",
       "3  0.504899    0.5    ...       0.5      0.5            0.5            0.5   \n",
       "4  0.500000    0.5    ...       0.5      0.5            0.5            0.5   \n",
       "\n",
       "   w_errors  w_special_keywords  w_xr_context  w_machine  w_doclen   w_total  \n",
       "0       0.5            0.501308      0.500000        0.5      3535  0.622490  \n",
       "1       0.5            0.502630      0.500000        0.5      8336  0.622510  \n",
       "2       0.5            0.500000      0.500000        0.5        74  0.630843  \n",
       "3       0.5            0.806442      0.720238        0.5       147  0.647684  \n",
       "4       0.5            0.500000      0.500000        0.5      1229  0.623353  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>w_name</th>\n",
       "      <th>w_name_desc</th>\n",
       "      <th>w_desc</th>\n",
       "      <th>w_lib</th>\n",
       "      <th>w_return_vals</th>\n",
       "      <th>w_env</th>\n",
       "      <th>w_files</th>\n",
       "      <th>w_exit_status</th>\n",
       "      <th>w_diagnostics</th>\n",
       "      <th>w_errors</th>\n",
       "      <th>w_special_keywords</th>\n",
       "      <th>w_xr_context</th>\n",
       "      <th>w_machine</th>\n",
       "      <th>w_doclen</th>\n",
       "      <th>w_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "      <td>2448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.996324</td>\n",
       "      <td>13.892157</td>\n",
       "      <td>13.503676</td>\n",
       "      <td>0.608854</td>\n",
       "      <td>0.591422</td>\n",
       "      <td>0.503225</td>\n",
       "      <td>0.503276</td>\n",
       "      <td>0.511072</td>\n",
       "      <td>0.503371</td>\n",
       "      <td>0.515782</td>\n",
       "      <td>0.508199</td>\n",
       "      <td>0.502594</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.514202</td>\n",
       "      <td>0.506785</td>\n",
       "      <td>0.500204</td>\n",
       "      <td>2524.439134</td>\n",
       "      <td>0.627022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.173821</td>\n",
       "      <td>33.927249</td>\n",
       "      <td>36.235223</td>\n",
       "      <td>0.205312</td>\n",
       "      <td>0.152930</td>\n",
       "      <td>0.012224</td>\n",
       "      <td>0.038461</td>\n",
       "      <td>0.056123</td>\n",
       "      <td>0.030938</td>\n",
       "      <td>0.070103</td>\n",
       "      <td>0.056711</td>\n",
       "      <td>0.025998</td>\n",
       "      <td>0.028089</td>\n",
       "      <td>0.055809</td>\n",
       "      <td>0.035020</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>8786.578076</td>\n",
       "      <td>0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.622459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500314</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>228.750000</td>\n",
       "      <td>0.622504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500943</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>589.500000</td>\n",
       "      <td>0.624363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.646715</td>\n",
       "      <td>0.502740</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503043</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1754.250000</td>\n",
       "      <td>0.630819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938770</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998989</td>\n",
       "      <td>0.910067</td>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.989540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>113084.000000</td>\n",
       "      <td>0.660942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           section     indegree    outdegree       w_name  w_name_desc  \\\n",
       "count  2448.000000  2448.000000  2448.000000  2448.000000  2448.000000   \n",
       "mean      3.996324    13.892157    13.503676     0.608854     0.591422   \n",
       "std       3.173821    33.927249    36.235223     0.205312     0.152930   \n",
       "min       0.000000     0.000000     0.000000     0.500000     0.500000   \n",
       "25%       2.000000     1.000000     0.000000     0.500000     0.500000   \n",
       "50%       4.000000     4.000000     5.000000     0.500000     0.500000   \n",
       "75%       8.000000    13.000000    11.000000     0.500000     0.646715   \n",
       "max      10.000000   394.000000   355.000000     1.000000     1.000000   \n",
       "\n",
       "            w_desc        w_lib  w_return_vals        w_env      w_files  \\\n",
       "count  2448.000000  2448.000000    2448.000000  2448.000000  2448.000000   \n",
       "mean      0.503225     0.503276       0.511072     0.503371     0.515782   \n",
       "std       0.012224     0.038461       0.056123     0.030938     0.070103   \n",
       "min       0.500000     0.500000       0.500000     0.500000     0.500000   \n",
       "25%       0.500314     0.500000       0.500000     0.500000     0.500000   \n",
       "50%       0.500943     0.500000       0.500000     0.500000     0.500000   \n",
       "75%       0.502740     0.500000       0.500000     0.500000     0.500000   \n",
       "max       0.938770     0.999980       1.000000     0.995826     1.000000   \n",
       "\n",
       "       w_exit_status  w_diagnostics     w_errors  w_special_keywords  \\\n",
       "count    2448.000000    2448.000000  2448.000000         2448.000000   \n",
       "mean        0.508199       0.502594     0.504132            0.514202   \n",
       "std         0.056711       0.025998     0.028089            0.055809   \n",
       "min         0.500000       0.500000     0.500000            0.500000   \n",
       "25%         0.500000       0.500000     0.500000            0.500000   \n",
       "50%         0.500000       0.500000     0.500000            0.500000   \n",
       "75%         0.500000       0.500000     0.500000            0.503043   \n",
       "max         1.000000       0.998989     0.910067            0.998759   \n",
       "\n",
       "       w_xr_context    w_machine       w_doclen      w_total  \n",
       "count   2448.000000  2448.000000    2448.000000  2448.000000  \n",
       "mean       0.506785     0.500204    2524.439134     0.627022  \n",
       "std        0.035020     0.010106    8786.578076     0.005660  \n",
       "min        0.500000     0.500000      22.000000     0.622459  \n",
       "25%        0.500000     0.500000     228.750000     0.622504  \n",
       "50%        0.500000     0.500000     589.500000     0.624363  \n",
       "75%        0.500000     0.500000    1754.250000     0.630819  \n",
       "max        0.989540     1.000000  113084.000000     0.660942  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'name', 'section', 'rank', 'indegree', 'outdegree', 'w_name',\n",
       "       'w_name_desc', 'w_desc', 'w_lib', 'w_return_vals', 'w_env', 'w_files',\n",
       "       'w_exit_status', 'w_diagnostics', 'w_errors', 'w_special_keywords',\n",
       "       'w_xr_context', 'w_machine', 'w_doclen', 'w_total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data.ix[:, 6:-5]\n",
    "y = data.ix[:, [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['w_name', 'w_name_desc', 'w_desc', 'w_lib', 'w_return_vals', 'w_env',\n",
       "       'w_files', 'w_exit_status', 'w_diagnostics', 'w_errors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rank'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values.ravel(), test_size=0.20, random_state=43)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(C=1.0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54469987228607919"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53061224489795922"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.7154569   1.85346932 -0.22117938 -0.24058422  0.73889749 -0.60951709\n",
      "  0.78978051 -1.31374325 -0.3296918  -0.74217832]\n"
     ]
    }
   ],
   "source": [
    "print(logistic_model.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.91492825])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic_model.coef_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(X_train)\n",
    "std_X_train = scalar.transform(X_train)\n",
    "std__X_val = scalar.transform(X_val)\n",
    "std_X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(16,32,64,32,16,8,2), solver='sgd', momentum=0.9, learning_rate='adaptive', max_iter=10000, verbose=True,activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.69209806\n",
      "Iteration 2, loss = 1.64762693\n",
      "Iteration 3, loss = 1.63059086\n",
      "Iteration 4, loss = 1.61902613\n",
      "Iteration 5, loss = 1.61429492\n",
      "Iteration 6, loss = 1.61053517\n",
      "Iteration 7, loss = 1.60697122\n",
      "Iteration 8, loss = 1.60372353\n",
      "Iteration 9, loss = 1.60067840\n",
      "Iteration 10, loss = 1.59768400\n",
      "Iteration 11, loss = 1.59466961\n",
      "Iteration 12, loss = 1.59205000\n",
      "Iteration 13, loss = 1.58898227\n",
      "Iteration 14, loss = 1.58646557\n",
      "Iteration 15, loss = 1.58383108\n",
      "Iteration 16, loss = 1.58158413\n",
      "Iteration 17, loss = 1.57922127\n",
      "Iteration 18, loss = 1.57693969\n",
      "Iteration 19, loss = 1.57436528\n",
      "Iteration 20, loss = 1.57216023\n",
      "Iteration 21, loss = 1.57006410\n",
      "Iteration 22, loss = 1.56821340\n",
      "Iteration 23, loss = 1.56601211\n",
      "Iteration 24, loss = 1.56436734\n",
      "Iteration 25, loss = 1.56253131\n",
      "Iteration 26, loss = 1.56063826\n",
      "Iteration 27, loss = 1.55910293\n",
      "Iteration 28, loss = 1.55769432\n",
      "Iteration 29, loss = 1.55599383\n",
      "Iteration 30, loss = 1.55447783\n",
      "Iteration 31, loss = 1.55310477\n",
      "Iteration 32, loss = 1.55156959\n",
      "Iteration 33, loss = 1.55034725\n",
      "Iteration 34, loss = 1.54901052\n",
      "Iteration 35, loss = 1.54779506\n",
      "Iteration 36, loss = 1.54679352\n",
      "Iteration 37, loss = 1.54555856\n",
      "Iteration 38, loss = 1.54514294\n",
      "Iteration 39, loss = 1.54359867\n",
      "Iteration 40, loss = 1.54246244\n",
      "Iteration 41, loss = 1.54157696\n",
      "Iteration 42, loss = 1.54069732\n",
      "Iteration 43, loss = 1.53994267\n",
      "Iteration 44, loss = 1.53885100\n",
      "Iteration 45, loss = 1.53817567\n",
      "Iteration 46, loss = 1.53762646\n",
      "Iteration 47, loss = 1.53737749\n",
      "Iteration 48, loss = 1.53612516\n",
      "Iteration 49, loss = 1.53553129\n",
      "Iteration 50, loss = 1.53494948\n",
      "Iteration 51, loss = 1.53425936\n",
      "Iteration 52, loss = 1.53376372\n",
      "Iteration 53, loss = 1.53314575\n",
      "Iteration 54, loss = 1.53264973\n",
      "Iteration 55, loss = 1.53234219\n",
      "Iteration 56, loss = 1.53167133\n",
      "Iteration 57, loss = 1.53138587\n",
      "Iteration 58, loss = 1.53114443\n",
      "Iteration 59, loss = 1.53060005\n",
      "Iteration 60, loss = 1.53005913\n",
      "Iteration 61, loss = 1.52981676\n",
      "Iteration 62, loss = 1.52936047\n",
      "Iteration 63, loss = 1.52916735\n",
      "Iteration 64, loss = 1.52876055\n",
      "Iteration 65, loss = 1.52851341\n",
      "Iteration 66, loss = 1.52845518\n",
      "Iteration 67, loss = 1.52815174\n",
      "Iteration 68, loss = 1.52811870\n",
      "Iteration 69, loss = 1.52745965\n",
      "Iteration 70, loss = 1.52730168\n",
      "Iteration 71, loss = 1.52720980\n",
      "Iteration 72, loss = 1.52691302\n",
      "Iteration 73, loss = 1.52700067\n",
      "Iteration 74, loss = 1.52697525\n",
      "Iteration 75, loss = 1.52635612\n",
      "Iteration 76, loss = 1.52640376\n",
      "Iteration 77, loss = 1.52595557\n",
      "Iteration 78, loss = 1.52589151\n",
      "Iteration 79, loss = 1.52590834\n",
      "Iteration 80, loss = 1.52570967\n",
      "Iteration 81, loss = 1.52559140\n",
      "Iteration 82, loss = 1.52545941\n",
      "Iteration 83, loss = 1.52532273\n",
      "Iteration 84, loss = 1.52523079\n",
      "Iteration 85, loss = 1.52506998\n",
      "Iteration 86, loss = 1.52498406\n",
      "Iteration 87, loss = 1.52517914\n",
      "Iteration 88, loss = 1.52479588\n",
      "Iteration 89, loss = 1.52473697\n",
      "Iteration 90, loss = 1.52468137\n",
      "Iteration 91, loss = 1.52463062\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000200\n",
      "Iteration 92, loss = 1.52448359\n",
      "Iteration 93, loss = 1.52442388\n",
      "Iteration 94, loss = 1.52441426\n",
      "Iteration 95, loss = 1.52438171\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000040\n",
      "Iteration 96, loss = 1.52437769\n",
      "Iteration 97, loss = 1.52435948\n",
      "Iteration 98, loss = 1.52436288\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000008\n",
      "Iteration 99, loss = 1.52434846\n",
      "Iteration 100, loss = 1.52434849\n",
      "Iteration 101, loss = 1.52434681\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000002\n",
      "Iteration 102, loss = 1.52434522\n",
      "Iteration 103, loss = 1.52434535\n",
      "Iteration 104, loss = 1.52434496\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 105, loss = 1.52434479\n",
      "Iteration 106, loss = 1.52434470\n",
      "Iteration 107, loss = 1.52434469\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(16, 32, 64, 32, 16, 8, 2),\n",
       "       learning_rate='adaptive', learning_rate_init=0.001, max_iter=10000,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25510204081632654"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26309067688378035"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=800, max_depth=25, max_features='log2', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=25, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=800, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54846938775510201"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323116219667944"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09562209,  0.09380033,  0.17785503,  0.11716764,  0.1602549 ,\n",
       "        0.00320034,  0.02354381,  0.0049912 ,  0.02229671,  0.00837976,\n",
       "        0.00604363,  0.01497333,  0.07683277,  0.02514093,  0.00018769,\n",
       "        0.16970983])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier(learning_rate=0.01, n_estimators=700, max_depth=32, max_features='log2', min_samples_split=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=32,\n",
       "              max_features='log2', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=700, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99744572158365263"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63775510204081631"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08882333,  0.08075878,  0.03556295,  0.07939071,  0.20276349,\n",
       "        0.01530834,  0.05679428,  0.02783822,  0.1687047 ,  0.24405519])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697318007663\n",
      "0.579081632653\n"
     ]
    }
   ],
   "source": [
    "etc = ExtraTreeClassifier(max_depth=20)\n",
    "etc.fit(X_train, y_train)\n",
    "print(etc.score(X_train, y_train))\n",
    "print(etc.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05635238,  0.06818842,  0.33420234,  0.17317662,  0.06510057,\n",
       "        0.00389701,  0.0103187 ,  0.01213399,  0.03200929,  0.0113986 ,\n",
       "        0.01344729,  0.02126289,  0.07952058,  0.02159589,  0.        ,\n",
       "        0.09739542])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5653061224489796"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5653061224489796"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboost.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19591836734693877"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52857142857142858"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
